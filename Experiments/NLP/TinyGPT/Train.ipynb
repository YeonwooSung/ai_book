{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyM4tANEoQBZD3nu74y6xySQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iMH4cIE86FRi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735365635381,"user_tz":-540,"elapsed":16154,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"bcfc4a72-bcdf-40bd-a850-261332a814e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["!pip3 install tokenizers wandb sentencepiece triton"],"metadata":{"id":"FBTlwAz07qvf","executionInfo":{"status":"ok","timestamp":1735365644419,"user_tz":-540,"elapsed":9041,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ac31e970-96bd-469c-d8eb-a6cef367be19"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Collecting triton\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.27.0)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n","Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton\n","Successfully installed triton-3.1.0\n"]}]},{"cell_type":"code","source":["!pip3 install transformers huggingface-hub tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"df_3VUzL7vEB","executionInfo":{"status":"ok","timestamp":1735365648741,"user_tz":-540,"elapsed":4325,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"c9f799c2-f034-4021-a0b2-4cc0a1c5268b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n","Collecting tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.8.0\n"]}]},{"cell_type":"code","source":["!pip3 install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsxwyby7AUgC","executionInfo":{"status":"ok","timestamp":1735365653187,"user_tz":-540,"elapsed":4448,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"b480ea23-e8c7-4ecf-e63b-fa4222efb5c7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["import os\n","\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Research')\n","os.chdir('LLM')\n","os.chdir('TinyLLM')"],"metadata":{"id":"D613nlta7wzS","executionInfo":{"status":"ok","timestamp":1735365653187,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["OUTPUT_DIR = './outputs/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"],"metadata":{"id":"GaCLZWGL7zzs","executionInfo":{"status":"ok","timestamp":1735365653484,"user_tz":-540,"elapsed":298,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2MZpfIR8ZUM","executionInfo":{"status":"ok","timestamp":1735365653484,"user_tz":-540,"elapsed":6,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"fdc180d9-352d-4215-b509-a38154e45ba0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec 28 06:00:53 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              44W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["# CFG"],"metadata":{"id":"zhA82h5s8pEW"}},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=True\n","    competition='PPPM'\n","    _wandb_kernel='bluehills'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"bert-base-uncased\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=50 # [0, 50, 100]\n","    epochs=5\n","    encoder_lr=1e-5 #2e-5\n","    decoder_lr=1e-5 #2e-5\n","    min_lr=5e-7\n","    eps=5e-7\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.15\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=44\n","    train_all_index=20\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n","    train=True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"],"metadata":{"id":"vBZv8y2E8ZLy","executionInfo":{"status":"ok","timestamp":1735365653777,"user_tz":-540,"elapsed":295,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    import wandb\n","    try:\n","        # from kaggle_secrets import UserSecretsClient\n","        # user_secrets = UserSecretsClient()\n","        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        # wandb.login(key=secret_value_0)\n","        print('login to wandb')\n","        wandb.login()\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='TinyLLM-Train',\n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"PZKMhi5h8ufc","executionInfo":{"status":"ok","timestamp":1659853914816,"user_tz":-540,"elapsed":9127,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"a1bbf140-e771-47de-c846-a478a35fdaa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["login to wandb\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbluehills\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/My Drive/Research/wandb/run-20220807_063152-3s9p7xvx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/bluehills/Transformer-Anatomy/runs/3s9p7xvx\" target=\"_blank\">bert-base-uncased</a></strong> to <a href=\"https://wandb.ai/bluehills/Transformer-Anatomy\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Library"],"metadata":{"id":"7-zO358s8qnF"}},{"cell_type":"code","source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","from math import sqrt\n","from dataclasses import dataclass\n","from typing import Optional, Tuple\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import logging\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","import torch.cuda.amp as amp\n","import torch.multiprocessing as mp\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","from torch.distributed import init_process_group, destroy_process_group\n","import torch.distributed as dist\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForTokenClassification\n","import tiktoken\n","\n","import datasets\n","import huggingface_hub\n","import matplotlib.font_manager as font_manager\n","import matplotlib.pyplot as plt\n","from IPython.display import set_matplotlib_formats\n","\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8dPVpoF8qXy","executionInfo":{"status":"ok","timestamp":1735365665971,"user_tz":-540,"elapsed":12195,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"b2e2c47e-f6ad-4fb4-cbca-cfeed7542282"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.__version__: 2.5.1+cu121\n","tokenizers.__version__: 0.21.0\n","transformers.__version__: 4.47.1\n","env: TOKENIZERS_PARALLELISM=true\n"]}]},{"cell_type":"markdown","source":["# Utils"],"metadata":{"id":"ZA0nmTqf9RO6"}},{"cell_type":"code","source":["# ====================================================\n","# Utils\n","# ====================================================\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"UrNo7WPP7zsr","executionInfo":{"status":"ok","timestamp":1735365665971,"user_tz":-540,"elapsed":5,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Model Args"],"metadata":{"id":"TKakTD9ix-qB"}},{"cell_type":"code","source":["@dataclass\n","class ModelArgs:\n","    dim: int = 768 #256 #128\n","    n_layers: int = 12 # Llama 3 8b uses 32\n","    n_heads: int = 12 # Llama 3 8b uses 32\n","    n_kv_heads: Optional[int] = 4 # Llama 3 8b's uses 8\n","    vocab_size: int = 50304 #512 # Llama 3 uses a more complicated tokenizer of length 128256\n","    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2. Llama 3 8b's uses 1024\n","    ffn_dim_multiplier: Optional[float] = None # Llama 3 8b's uses 1.3, which changes the ending hidden_dim slightly\n","    norm_eps: float = 1e-5\n","    rope_theta: float = 10000 # Llama 3 8b uses 500000\n","    max_batch_size: int = 16\n","    grad_accum_steps: int = 4\n","    max_seq_len: int = 1024 #256 # Llama 3 8b trained with 8192 but their maximum kv cache chunk size during inference is 2048\n","    dropout_rate: float = 0.1\n","    bfloat_supported: bool = True #does the machine support bfloat16 for autocast\n","    flash_attn_supported: bool = False #does the mahine support Flahs Attention?\n"],"metadata":{"id":"d3Y0z9IVxhzO","executionInfo":{"status":"ok","timestamp":1735365705657,"user_tz":-540,"elapsed":336,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## SLM Helper"],"metadata":{"id":"mHn4QrM2yFUL"}},{"cell_type":"code","source":["class RMSNorm(torch.nn.Module):\n","    def __init__(self, dim: int, eps: float = 1e-6):\n","        super().__init__()\n","        self.eps = eps\n","        self.weight = nn.Parameter(torch.ones(dim))\n","\n","    def _norm(self, x):\n","        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n","\n","    def forward(self, x):\n","        output = self._norm(x.float()).type_as(x)\n","        return output * self.weight"],"metadata":{"id":"LsRyru4Gxhwk","executionInfo":{"status":"ok","timestamp":1735365718253,"user_tz":-540,"elapsed":472,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def create_causal_mask(seq_len: int, device: str):\n","    mask = torch.full(\n","      (seq_len, seq_len),\n","      float(\"-inf\")\n","    )\n","    mask = torch.triu(mask, diagonal=1)\n","    return(mask.to(device))\n","\n","\n","def precompute_rotary_embeddings(head_dim: int, seq_len: int, device: str, theta: float = 10000.0):\n","    #default theta set to 10,000. recomended value\n","\n","    #STEP 1: Compute the theta_i values\n","    #formula for theta_i(freqs) is theta ^ (-(2(i - 1)/dim)) where i = 1, 2, ... dim/2\n","    #torch.arrange gived number from 0 to end integer\n","\n","    freqs = 1.0 / (theta ** (torch.arange(0, head_dim, 2)[: (head_dim // 2)].float() / head_dim))\n","    #freqs shape will be size head_dim/2\n","\n","    #print(f'freqs: {freqs.shape}\\n{freqs}\\n')\n","\n","    #STEP 2: Compute the m_i * theta_i matrix\n","    #just an array of numbers from 0 to 2xseq_length\n","    # why 2xseq_length? - so we can project into the generated tokens\n","    t = torch.arange(seq_len, dtype=torch.float32)\n","    #print(f't: {t.shape}\\n{t}\\n')\n","\n","    freqs = torch.outer(t, freqs)   #outer product of tensors\n","    #print(f'freqs: {freqs.shape}\\n{freqs}\\n')\n","    #this shape will be a matrix of 2xseq_length, head_dim\n","\n","    # STEP 3: return the cosing and sine values for the m_i * theta_i computed earlier\n","    # torch.ones_like(freqs)  #returns tensor of ones with same shape as freqs\n","    # torch.polar(abs, angle) - returns a complex tensor - abs⋅cos(angle)+abs⋅sin(angle)⋅j\n","\n","    freqs_complex = torch.polar(torch.ones_like(freqs), freqs)[:seq_len]\n","    #print(f'freqs_complex: {freqs_complex.shape}\\n{freqs_complex}')\n","\n","    return(freqs_complex.to(device))\n","\n","\n","def apply_rotary_embeddings(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor, ) -> Tuple[torch.Tensor, torch.Tensor]:\n","    #STEP 1: group pairs of the q and k tensors and move them into complex numbers e.f. [x1, x2, x3, x4] => [[x1 + ix2], [x3 + ix4]]\n","    # we only apply the ROPE Embeddings to the q and k matrices, not the v matrix\n","    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n","    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n","\n","    #STEP 2: reshape the precomputed ROPE Embeddings into a form we can multiply with\n","    ndim = xq_.ndim\n","    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(xq_.shape)]\n","    freqs_cis = freqs_cis.view(*shape)\n","\n","    #STEP 3: Multiply the reshpaed q and k matrices and reshape back into the original shape\n","    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n","    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n","\n","    return xq_out.type_as(xq), xk_out.type_as(xk)"],"metadata":{"id":"GhG0fqezyHwA","executionInfo":{"status":"ok","timestamp":1735365718538,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"rsQ5d6CEydbW"}},{"cell_type":"code","source":["params = ModelArgs()"],"metadata":{"id":"l1BnL6QYyefK","executionInfo":{"status":"ok","timestamp":1735365719549,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, args: ModelArgs, device):\n","        super().__init__()\n","        self.n_heads = args.n_heads\n","        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n","        self.dim = args.dim\n","        self.head_dim = args.dim // args.n_heads\n","\n","        attn_shape = (self.n_heads + 2 * args.n_kv_heads) * self.head_dim\n","\n","        # Attention Weight Matrix\n","        self.qkv_attn = nn.Linear(args.dim, attn_shape, bias=False)\n","        #Output Weight Matrix\n","        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n","\n","\n","        self.cache_k = torch.zeros(\n","            (args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim),\n","            requires_grad = False\n","        ).to(device)\n","        self.cache_v = torch.zeros(\n","            (args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim),\n","            requires_grad = False\n","        ).to(device)\n","\n","\n","    def forward(self,  x: torch.Tensor,  freqs_cis: torch.Tensor, mask: Optional[torch.Tensor], start_pos: int = None,  ):\n","        num_batches, seqlen, _ = x.shape\n","        q_per_kv = self.n_heads // self.n_kv_heads\n","\n","\n","        # e.g. for dim = 768, num_q_heads = 12, num_kv_heads = 4\n","        # this would create a matix with dimensions B, T, (768 + 256 + 256)\n","        qkv = self.qkv_attn(x)\n","\n","        # create a view with B, T, 4, 5, 64, (768/12)\n","        qkv = qkv.view(num_batches, seqlen, self.n_kv_heads, q_per_kv + 2, self.head_dim)\n","\n","        #now split\n","        q, k, v = qkv.split((q_per_kv, 1, 1), dim=-2)\n","\n","        q = q.reshape(num_batches, seqlen, -1, self.head_dim)  # (B, T, nh_q, hs)\n","        k = k.reshape(num_batches, seqlen, -1, self.head_dim)\n","        v = v.reshape(num_batches, seqlen, -1, self.head_dim)\n","\n","        q, k = apply_rotary_embeddings(q, k, freqs_cis=freqs_cis)\n","\n","        if start_pos is not None:\n","            #KV CACHE FOR INFERENCE\n","            #this is from the LLAMA3 code\n","            # make sure our cache is on the right device\n","            self.cache_k = self.cache_k.to(q)\n","            self.cache_v = self.cache_v.to(q)\n","\n","            # set the values in our cache according to the current input\n","            self.cache_k[:num_batches, start_pos : start_pos + seqlen] = k\n","            self.cache_v[:num_batches, start_pos : start_pos + seqlen] = v\n","\n","            # grab our key and value matrixes which have a longer sequence length than our queries\n","            keys = self.cache_k[:num_batches, : start_pos + seqlen]\n","            values = self.cache_v[:num_batches, : start_pos + seqlen]\n","        else:\n","            # TRAINING\n","            keys, values = k, v\n","\n","        scale = 1/q.shape[-1]**0.5\n","        q = q.transpose(1, 2)\n","        k = k.transpose(1, 2)\n","        v = v.transpose(1, 2)\n","        if q.size() != k.size():\n","            k = k.repeat_interleave(q.shape[1]//k.shape[1], dim=1)\n","            v = v.repeat_interleave(q.shape[1]//v.shape[1], dim=1)\n","        #automatically uses flash attention and applies softmax scale\n","        o = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=mask, dropout_p=0.0, is_causal=mask is None)\n","        #o = o.transpose(1,2).contiguous().view(num_batches, seqlen, self.dim)\n","        o = o.transpose(1,2).reshape(num_batches, seqlen, self.dim)\n","\n","        return self.wo(o)"],"metadata":{"id":"pAw5bjyfyHtQ","executionInfo":{"status":"ok","timestamp":1735365719827,"user_tz":-540,"elapsed":2,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, ffn_dim_multiplier: Optional[float],):\n","        super().__init__()\n","        # custom dim factor multiplier that ensures we're using a multiple of 256, likely for hardware efficiency reasons\n","        hidden_dim = int(2 * hidden_dim / 3)\n","        if ffn_dim_multiplier is not None:\n","            hidden_dim = int(ffn_dim_multiplier * hidden_dim)\n","        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n","\n","        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n","        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n","        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n","\n","    def forward(self, x):\n","        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n","\n","\n","#Repeating Block\n","class TransformerBlock(nn.Module):\n","    def __init__(self, layer_id: int, args: ModelArgs, device):\n","        super().__init__()\n","        self.n_heads = args.n_heads\n","        self.dim = args.dim\n","        self.head_dim = args.dim // args.n_heads\n","        self.attention = Attention(args, device)\n","        self.feed_forward = FeedForward(\n","            dim=args.dim,\n","            hidden_dim=4 * args.dim,\n","            multiple_of=args.multiple_of,\n","            ffn_dim_multiplier=args.ffn_dim_multiplier,\n","        )\n","        self.layer_id = layer_id\n","        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n","        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n","        self.dropout_rate = args.dropout_rate\n","\n","    def forward(self, x: torch.Tensor, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor], start_pos: int = None, training = False, ):\n","        # our two residual connections, plus dropout which will only happen if we're training\n","        #RESIDUAL CONNECTION 1\n","        h = x # save the inputs for the residual connection\n","        #apply RMS Norm to the inputs\n","        x = self.attention_norm(x)\n","        #apply the attention layer\n","        x = self.attention(x, freqs_cis, mask, start_pos)\n","        #Apply the Dropout ONLY IF WE'RE IN THE TRAINING LOOP\n","        x = F.dropout(x, p=self.dropout_rate, training=training)\n","        #make the residual connection\n","        h = h + x\n","\n","        #RESIDUAL CONNECTION 1\n","        out = h # save the inputs for the residual connection\n","        #apply RMS Norm to the inputs\n","        h = self.ffn_norm(h)\n","        #apply the feed forward layer\n","        h = self.feed_forward(h)\n","        #Apply the Dropout ONLY IF WE'RE IN THE TRAINING LOOP\n","        h = F.dropout(h, p=self.dropout_rate, training=training)\n","        #make the residual connection\n","        out = out + h\n","\n","        return out"],"metadata":{"id":"M052ejo_yHqB","executionInfo":{"status":"ok","timestamp":1735365721003,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class LLM(nn.Module):\n","    def __init__(self, params: ModelArgs, tokenizer, device):\n","        super().__init__()\n","        self.params = params\n","        self.vocab_size = params.vocab_size\n","        self.n_layers = params.n_layers\n","        self.max_seq_len = params.max_seq_len\n","        self.tokenizer = tokenizer\n","        self.device = device\n","\n","        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n","\n","        self.layers = torch.nn.ModuleList()\n","        for layer_id in range(params.n_layers):\n","            self.layers.append(TransformerBlock(layer_id, params, device))\n","\n","        # final norm and linear layer\n","        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n","        self.output = nn.Linear(\n","            params.dim,\n","            params.vocab_size,\n","            bias=False)\n","\n","        # weight sharing scheme\n","        # this ensures that the embedding layer and the output layers share weights\n","        self.tok_embeddings.weight = self.output.weight\n","\n","        # precompute RoPE frequencies\n","        self.freqs_cis = precompute_rotary_embeddings(\n","            params.dim // params.n_heads,\n","            params.max_seq_len * 2,\n","            self.device,\n","            params.rope_theta,)\n","\n","        # precompute the causal attention mask\n","        mask = create_causal_mask(params.max_seq_len, self.device)\n","\n","        self.register_buffer('mask', mask, persistent=True) #persistent ensures this gets saved in the state_dict\n","\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","    def forward(self, # specifically for training. this is what you saw in section 1\n","                tokens: torch.Tensor,\n","                targets: torch.Tensor):\n","        bsz, seqlen = tokens.shape\n","        assert tokens.shape == targets.shape\n","        assert seqlen == self.max_seq_len\n","\n","        # initialize the first residual state\n","        h = self.tok_embeddings(tokens)\n","\n","        # grab precomputes freqs_cis\n","        freqs_cis = self.freqs_cis.to(h.device)\n","        freqs_cis = self.freqs_cis[:seqlen]\n","\n","        # run the residual state through each layer\n","        for layer in self.layers:\n","            h = layer(\n","                h,\n","                freqs_cis,\n","                self.mask,\n","                start_pos = None,\n","                training = True\n","            )\n","\n","        # norm the final output then get the logits\n","        h = self.norm(h)\n","        logits = self.output(h).float()\n","\n","        loss = self.criterion(\n","            logits.view(bsz * seqlen, self.vocab_size),\n","            targets.reshape(bsz * seqlen))\n","\n","        return logits, loss\n","\n","    @torch.inference_mode()\n","    def forward_inference(self,\n","                          tokens: torch.Tensor,\n","                          start_pos: int,\n","                          max_context_window: int,\n","                         ):\n","        _bsz, seqlen = tokens.shape\n","        h = self.tok_embeddings(tokens)\n","        self.freqs_cis = self.freqs_cis.to(h.device)\n","        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n","\n","        mask = self.mask[:seqlen, :seqlen]\n","        # When performing key-value caching, we compute the attention scores\n","        # only for the new sequence. Thus, the matrix of scores is of size\n","        # (seqlen, cache_len + seqlen), and the only masked entries are (i, j) for\n","        # j > cache_len + i, since row i corresponds to token cache_len + i.\n","        mask = torch.hstack(\n","            [torch.zeros((seqlen, start_pos), device=tokens.device), mask]\n","        ).type_as(h)\n","        #print(seqlen)\n","        #print(start_pos)\n","        #print( mask.shape)\n","\n","\n","        for layer in self.layers:\n","            h = layer(\n","                h,\n","                freqs_cis,\n","                mask,\n","                start_pos = start_pos\n","            )\n","        h = self.norm(h)\n","        logits = self.output(h).float()\n","        return logits\n","\n","    @torch.inference_mode() # no need to keep track of gradients during inference\n","    def Sampler(\n","        self,\n","        logits: torch.Tensor, # shape (batch_size, input_len, vocab_size)\n","        temperature: float, # controls how boring vs random the outputs should be\n","        top_p: float, # the maximum cumulative probability of output options we're willing to consider\n","        top_k: int, # the maximum number of output options we're willing to consider\n","    ) -> torch.Tensor:\n","        \"\"\"\n","        The Sampler function is responsible for generating token predictions\n","        It supports temperature scaling, top-p (nucleus) sampling, and top-k sampling\n","        \"\"\"\n","        # Select the last element for each sequence.\n","        logits = logits[:,-1,:] # (batch_size, input_len, vocab_size) -> (batch_size, vocab_size)\n","\n","        # Apply temperature scaling\n","        logits.div_(temperature) # (batch_size, vocab_size) / float -> (batch_size, vocab_size)\n","\n","        # Calculate probabilities with softmax.\n","        probs = torch.softmax(logits, dim=-1, dtype=torch.float) # dim=-1 is the vocab_size dimension that we calculate along\n","\n","        # sort the probabilities to for use in top-p & top-k. both are (batch_size, vocab_size)\n","        probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n","\n","        ### calculating top-p\n","        # creates same-size tensor of cumulatve probabilities instead of indivdiual probs\n","        probs_sum = torch.cumsum(probs_sort, dim=-1)\n","        # mask where 0's are top-p selections & 1's are to be excluded\n","        top_ps_mask = (probs_sum - probs_sort) > top_p\n","        # the original probabilities with excluded tokens changed to 0.0\n","        probs_sort = torch.where(top_ps_mask, 0, probs_sort)\n","\n","        ### calculating top_k\n","        # create a shape (vocab_size) tensor that just iterates up by 1's\n","        top_ks_mask = torch.arange(probs_idx.shape[-1], device=probs_idx.device)\n","        # expand our mask along the batch_size dimension to become size (batch_size, vocab_size)\n","        top_ks_mask = top_ks_mask.expand(probs_idx.shape[0], -1)\n","        # top_ks is a list of integers. we keep whichever entries in top_ks_mask are greater than their corresponding entries in top_ks\n","        top_ks_mask = top_ks_mask >= top_k\n","\n","        # we'll be combining top-p with top-k and using whichever gives us fewer tokens. a very conservative approach\n","        # this trims probs_sort to also fit within our top_k requirement\n","        probs_sort = torch.where(top_ks_mask, 0, probs_sort)\n","\n","        # Re-normalization so that total probabilities add up to 1\n","        probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n","\n","        # now we rearrange the modified probabilities in probs_sort back to their original order according to probs_idx\n","        probs = torch.gather(probs_sort, dim=-1, index=torch.argsort(probs_idx, dim=-1))\n","\n","        # samples from the distribution\n","        next_token_id = torch.multinomial(probs, num_samples=1)\n","\n","        return next_token_id # returns the predicted token\n","\n","    @torch.inference_mode()\n","    def generate(\n","        self,\n","        prompt: str,\n","        max_gen_len: int = None,\n","        temperature: float = 0.6, # default value in meta's code\n","        top_p: float = 0.9, # default value in meta's code\n","        top_k: int = params.vocab_size, # meta's code doesn't bother with topk\n","    ) -> str:\n","        \"\"\" Wrapper around sampler() that deals with manipulation of the sequence \"\"\"\n","\n","        max_context_window = self.max_seq_len\n","\n","        # encoding the prompt into token indices\n","        tokens = self.tokenizer.encode(prompt)\n","\n","        if max_gen_len is None:\n","            max_gen_len = self.max_seq_len - len(tokens)\n","        elif max_gen_len + len(tokens) > self.max_seq_len:\n","            print(f'capping max_gen_len at max_seq_len={self.max_seq_len} including input\\n')\n","            max_gen_len = self.max_seq_len - len(tokens)\n","\n","        # turning it into the right tensor shape\n","        tokens = torch.tensor(tokens, device=self.device)\n","        tokens = tokens.unsqueeze(0) if len(tokens.shape)==1 else tokens # jic we need to add a batch dimension\n","\n","        # the offset used for kv caching\n","        start_pos = max(tokens.shape[1] - max_context_window, 0)\n","\n","        for i in range(max_gen_len):\n","            # get the model's output logits and ignore the loss, which would be a NoneType object\n","            logits = self.forward_inference(\n","                tokens[:,-max_context_window:],\n","                start_pos = start_pos,\n","                max_context_window = max_context_window\n","            )\n","\n","            # sample the next token to be used from the logit distribution\n","            next_token = self.Sampler(\n","                logits = logits,\n","                temperature = temperature,\n","                top_p = top_p,\n","                top_k = top_k\n","            )\n","\n","            # add our new token to the sequence\n","            tokens = torch.cat((tokens, next_token), dim=1)\n","\n","            # iterate the offset used in kv caching\n","            if tokens.shape[1] >= max_context_window:\n","                start_pos += 1\n","\n","        # decode our list of tokens to an actual string\n","        output = self.tokenizer.decode(tokens.squeeze(0).tolist())\n","\n","        return output"],"metadata":{"id":"aDPEHXtuxht9","executionInfo":{"status":"ok","timestamp":1735365721382,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Data Loader"],"metadata":{"id":"fQshhUE9y1W5"}},{"cell_type":"code","source":["device_type = device.type"],"metadata":{"id":"JkpWQV1Oy5EO","executionInfo":{"status":"ok","timestamp":1735365721827,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# set up DDP (distributed data parallel).\n","# torchrun command sets the env variables RANK, LOCAL_RANK, and WORLD_SIZE\n","ddp = int(os.environ.get('RANK', -1)) != -1 # is this a ddp run?\n","if ddp:\n","    # use of DDP atm demands CUDA, we set the device appropriately according to rank\n","    assert torch.cuda.is_available(), \"for now i think we need CUDA for DDP\"\n","    init_process_group(backend='nccl')\n","    ddp_rank = int(os.environ['RANK'])\n","    ddp_local_rank = int(os.environ['LOCAL_RANK'])\n","    ddp_world_size = int(os.environ['WORLD_SIZE'])\n","    device = f'cuda:{ddp_local_rank}'\n","    torch.cuda.set_device(device)\n","    master_process = ddp_rank == 0 # this process will do logging, checkpointing etc.\n","else:\n","    # vanilla, non-DDP run\n","    ddp_rank = 0\n","    ddp_local_rank = 0\n","    ddp_world_size = 1\n","    master_process = True\n","    # attempt to autodetect device\n","    device = \"cpu\"\n","    if torch.cuda.is_available():\n","        device = \"cuda\"\n","    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n","        device = \"mps\"\n","print(f\"using device: {device}\")"],"metadata":{"id":"XA5mna-Iy2YR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735365722340,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"04d6fde6-b609-4c80-8baf-ecf7535fd6f2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cuda\n"]}]},{"cell_type":"code","source":["#DataLoader code\n","def load_tokens(filename):\n","    npt = np.load(filename)\n","    npt = npt.astype(np.int32)\n","    ptt = torch.tensor(npt, dtype=torch.long)\n","    return ptt\n","\n","\n","class DataLoaderLite:\n","    def __init__(self, B, T, process_rank, num_processes, split):\n","        self.B = B\n","        self.T = T\n","        self.process_rank = process_rank\n","        self.num_processes = num_processes\n","        assert split in {'train', 'val'}\n","\n","        # get the shard filenames\n","        data_root = \"edu_fineweb10B\"\n","        shards = os.listdir(data_root)\n","        shards = [s for s in shards if split in s]\n","        shards = sorted(shards)\n","        shards = [os.path.join(data_root, s) for s in shards]\n","        self.shards = shards\n","        assert len(shards) > 0, f\"no shards found for split {split}\"\n","        #if master_process:\n","        print(f\"found {len(shards)} shards for split {split} on device {device}\")\n","        self.reset()\n","\n","    def reset(self):\n","        # state, init at shard zero\n","        self.current_shard = 0\n","        self.tokens = load_tokens(self.shards[self.current_shard])\n","        self.current_position = self.B * self.T * self.process_rank\n","\n","    def next_batch(self):\n","        B, T = self.B, self.T\n","        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n","        x = (buf[:-1]).view(B, T) # inputs\n","        y = (buf[1:]).view(B, T) # targets\n","        # advance the position in the tensor\n","        self.current_position += B * T * self.num_processes\n","        # if loading the next batch would be out of bounds, advance to next shard\n","        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):\n","            self.current_shard = (self.current_shard + 1) % len(self.shards)\n","            self.tokens = load_tokens(self.shards[self.current_shard])\n","            self.current_position = B * T * self.process_rank\n","        return x, y"],"metadata":{"id":"48FyfXN5y9pE","executionInfo":{"status":"ok","timestamp":1735365722823,"user_tz":-540,"elapsed":1,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## Training Utils"],"metadata":{"id":"OzQm-7QGzLO7"}},{"cell_type":"code","source":["B = params.max_batch_size #16\n","T = params.max_seq_len #1024\n","train_loader = DataLoaderLite(B=B, T=T, process_rank=ddp_rank, num_processes=ddp_world_size, split=\"train\")\n","val_loader = DataLoaderLite(B=B, T=T, process_rank=ddp_rank, num_processes=ddp_world_size, split=\"val\")"],"metadata":{"id":"AcCc19f-HqYz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735365741894,"user_tz":-540,"elapsed":18633,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"487f423a-0214-45a6-cb77-3eab536a0597"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["found 99 shards for split train on device cuda\n","found 1 shards for split val on device cuda\n"]}]},{"cell_type":"code","source":["tokenizer = tiktoken.get_encoding(\"gpt2\")\n","eot = tokenizer._special_tokens['<|endoftext|>'] # end of text token"],"metadata":{"id":"f-UBU8n62CFI","executionInfo":{"status":"ok","timestamp":1735365742772,"user_tz":-540,"elapsed":880,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["#instantiate model\n","model = LLM(params, tokenizer, device)\n","model = model.to(device)\n","\n","#torch.compile\n","model = torch.compile(model)  #use torch.compile to speed things up\n","\n","#wrap the model in DDP\n","if ddp:\n","    model = DDP(model, device_ids=[ddp_local_rank])\n","\n","if master_process:\n","    s = sum(p.numel() for p in model.parameters())\n","    print(f\"{s} parameter model trained on 10 Billion tokens\")"],"metadata":{"id":"cNk_e7aMy2VS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735365746288,"user_tz":-540,"elapsed":3518,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"0207d3a6-bfef-427d-e2ac-e0fe9e71b88d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["114150144 parameter model trained on 10 Billion tokens\n"]}]},{"cell_type":"code","source":["@torch.no_grad()\n","def estimate_val_loss(model, batch_size, eval_iters = 10): # to estimate loss during the training loop\n","    out = {}\n","    model.eval() # sets model to eval mode\n","    #for split in ['train', 'val']:\n","    for split in ['val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            #X, Y = get_batch(split, batch_size)\n","            #logits, loss = model(X, targets=Y)\n","            #losses[k] = loss.item()\n","            #dl = get_dataloader(split, batch_size)\n","            #for s, t in dl:\n","            s, t = val_loader.next_batch()\n","            s, t = s.to(device), t.to(device)\n","            # if the GPU supports BFLOAT, autocast to BF16\n","            if (params.bfloat_supported):\n","              with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n","                logits, loss = model(s, targets=t)\n","                losses[k] = loss.item()\n","            else:\n","              logits, loss = model(s, targets=t)\n","              losses[k] = loss.item()\n","\n","        out[split] = losses.mean()\n","    model.train() # just resets to training mode\n","    return out"],"metadata":{"id":"ARcvAmTgNpKb","executionInfo":{"status":"ok","timestamp":1735365746288,"user_tz":-540,"elapsed":4,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#***************************************************\n","# how long we want to train for\n","#***************************************************\n","max_iters = 15000 #2000\n","# how often we want to check & see how our loss is doing\n","eval_interval = 50\n","\n","# Warmup setup\n","warmup_iters = 500  # Number of warmup iterations\n","warmup_factor = 1e-3  # Warmup factor (initial learning rate is multiplied by this factor)\n","\n","# create a PyTorch optimizer\n","lr_init = 6e-4\n","lr_final = lr_init * 0.1 # Minimum learning rate\n","weight_decay = 0.02\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr_init, weight_decay=weight_decay)"],"metadata":{"id":"b1CHphGEzS1l","executionInfo":{"status":"ok","timestamp":1735365746288,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def lr_lambda(current_iter):\n","    if current_iter < warmup_iters:\n","        # Warmup phase\n","        return warmup_factor + (1 - warmup_factor) * current_iter / warmup_iters\n","    else:\n","        # Cosine decay phase with minimum learning rate\n","        decay_iters = max_iters - warmup_iters\n","        cosine_decay = 0.5 * (1 + math.cos(math.pi * (current_iter - warmup_iters) / decay_iters))\n","        return max(cosine_decay, lr_final / lr_init)"],"metadata":{"id":"yJ8nZFMDzTk2","executionInfo":{"status":"ok","timestamp":1735365746288,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"],"metadata":{"id":"y6VJY3RizTiu","executionInfo":{"status":"ok","timestamp":1735365746288,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["## Train"],"metadata":{"id":"Y6DhWPrtzXCg"}},{"cell_type":"code","source":["start_time = time.time()\n","\n","# Enable anomaly detection. uncomment these lines if you need to do extensive debugging\n","#torch.autograd.set_detect_anomaly(True)\n","\n","for iter in range(max_iters):\n","    loss_accum = 0.0 #this is just for display purposes\n","    model.train()\n","    for microstep in range(params.grad_accum_steps):\n","        #dl = get_dataloader('train', params.max_batch_size)\n","        #for s, t in dl:\n","        s, t = train_loader.next_batch()\n","        s, t = s.to(device), t.to(device)\n","        #This might not be the official way to do this. If thing break in the future, look here\n","        if ddp:\n","            #model.require_backward_grad_sync = (microstep == params.grad_accum_steps - 1)\n","            if (microstep == params.grad_accum_steps - 1):\n","                #print(\"synching\")\n","                model.require_backward_grad_sync = True\n","        #if bfloat16 is supported, use it\n","        if (params.bfloat_supported):\n","            with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n","                logits, loss = model(s, targets=t)\n","        else:\n","            logits, loss = model(s, targets=t)\n","        loss = loss / params.grad_accum_steps\n","        loss.backward()\n","        loss_accum += loss.detach()\n","        norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  #clip gradients\n","        #optimizer.step() # update weights\n","        #optimizer.zero_grad() #REMEMBER TO ZERO THE GRADIENTS!!!\n","    if ddp:\n","        dist.all_reduce(loss_accum, op=dist.ReduceOp.AVG)\n","\n","    optimizer.step() # update weights\n","    optimizer.zero_grad() #REMEMBER TO ZERO THE GRADIENTS!!!\n","    # Update the learning rate\n","    scheduler.step()\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if iter % eval_interval == 0 or iter == max_iters - 1:\n","        current_time = time.time()\n","        elapsed_time = current_time - start_time\n","\n","        if master_process:\n","            #only estimate Val loss for the Master process\n","            losses = estimate_val_loss(model, params.max_batch_size)\n","            current_lr = optimizer.param_groups[0]['lr']\n","            print(f\"step {iter:04d}: lr {current_lr:.6f}, train loss {loss_accum:.4f}, val loss {losses['val']:.4f}, time elapsed: {elapsed_time:.2f} seconds\")"],"metadata":{"id":"tvOl3sjszSy8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735373598198,"user_tz":-540,"elapsed":7851913,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"bf56b594-c954-46a7-93ef-3d755aa59340"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["step 0000: lr 0.000002, train loss 11.0041, val loss 10.9982, time elapsed: 36.14 seconds\n","step 0050: lr 0.000062, train loss 8.6184, val loss 8.6349, time elapsed: 77.28 seconds\n","step 0100: lr 0.000122, train loss 7.6952, val loss 7.5110, time elapsed: 103.09 seconds\n","step 0150: lr 0.000182, train loss 7.7130, val loss 7.0836, time elapsed: 128.93 seconds\n","step 0200: lr 0.000242, train loss 6.6360, val loss 6.7255, time elapsed: 154.81 seconds\n","step 0250: lr 0.000301, train loss 6.3251, val loss 6.4910, time elapsed: 180.71 seconds\n","step 0300: lr 0.000361, train loss 6.1571, val loss 6.2282, time elapsed: 206.61 seconds\n","step 0350: lr 0.000421, train loss 5.8220, val loss 6.1237, time elapsed: 232.52 seconds\n","step 0400: lr 0.000481, train loss 5.8494, val loss 5.8538, time elapsed: 258.43 seconds\n","step 0450: lr 0.000541, train loss 5.7364, val loss 5.7070, time elapsed: 284.35 seconds\n","step 0500: lr 0.000600, train loss 5.6161, val loss 5.5538, time elapsed: 310.27 seconds\n","step 0550: lr 0.000600, train loss 5.3770, val loss 5.4526, time elapsed: 336.19 seconds\n","step 0600: lr 0.000600, train loss 5.1989, val loss 5.2950, time elapsed: 362.13 seconds\n","step 0650: lr 0.000600, train loss 5.0193, val loss 5.1673, time elapsed: 388.07 seconds\n","step 0700: lr 0.000600, train loss 4.9909, val loss 5.1694, time elapsed: 414.02 seconds\n","step 0750: lr 0.000600, train loss 5.1170, val loss 5.1342, time elapsed: 439.96 seconds\n","step 0800: lr 0.000599, train loss 5.1872, val loss 5.0983, time elapsed: 465.90 seconds\n","step 0850: lr 0.000599, train loss 4.9974, val loss 4.7809, time elapsed: 491.84 seconds\n","step 0900: lr 0.000599, train loss 4.8497, val loss 4.8520, time elapsed: 517.78 seconds\n","step 0950: lr 0.000599, train loss 4.6447, val loss 4.7708, time elapsed: 543.73 seconds\n","step 1000: lr 0.000598, train loss 4.6226, val loss 4.7234, time elapsed: 569.67 seconds\n","step 1050: lr 0.000598, train loss 4.5973, val loss 4.6915, time elapsed: 595.61 seconds\n","step 1100: lr 0.000597, train loss 4.4586, val loss 4.5485, time elapsed: 621.55 seconds\n","step 1150: lr 0.000597, train loss 4.4846, val loss 4.6453, time elapsed: 647.50 seconds\n","step 1200: lr 0.000597, train loss 4.6164, val loss 4.4566, time elapsed: 673.44 seconds\n","step 1250: lr 0.000596, train loss 4.5002, val loss 4.5304, time elapsed: 699.37 seconds\n","step 1300: lr 0.000595, train loss 4.4495, val loss 4.5147, time elapsed: 725.32 seconds\n","step 1350: lr 0.000595, train loss 4.3299, val loss 4.5132, time elapsed: 751.27 seconds\n","step 1400: lr 0.000594, train loss 4.2377, val loss 4.4686, time elapsed: 777.21 seconds\n","step 1450: lr 0.000594, train loss 4.2420, val loss 4.4120, time elapsed: 803.16 seconds\n","step 1500: lr 0.000593, train loss 4.4684, val loss 4.4049, time elapsed: 829.10 seconds\n","step 1550: lr 0.000592, train loss 4.3488, val loss 4.3254, time elapsed: 857.69 seconds\n","step 1600: lr 0.000592, train loss 4.3721, val loss 4.3835, time elapsed: 883.63 seconds\n","step 1650: lr 0.000591, train loss 4.3560, val loss 4.3139, time elapsed: 909.58 seconds\n","step 1700: lr 0.000590, train loss 4.1817, val loss 4.3333, time elapsed: 935.53 seconds\n","step 1750: lr 0.000589, train loss 4.1743, val loss 4.3161, time elapsed: 961.48 seconds\n","step 1800: lr 0.000588, train loss 4.2793, val loss 4.1818, time elapsed: 987.43 seconds\n","step 1850: lr 0.000587, train loss 4.1138, val loss 4.4343, time elapsed: 1013.37 seconds\n","step 1900: lr 0.000586, train loss 4.2651, val loss 4.2046, time elapsed: 1039.32 seconds\n","step 1950: lr 0.000585, train loss 4.3044, val loss 4.2470, time elapsed: 1065.25 seconds\n","step 2000: lr 0.000584, train loss 4.1157, val loss 4.1559, time elapsed: 1091.19 seconds\n","step 2050: lr 0.000583, train loss 4.0755, val loss 4.1587, time elapsed: 1117.13 seconds\n","step 2100: lr 0.000582, train loss 4.1743, val loss 4.1096, time elapsed: 1143.07 seconds\n","step 2150: lr 0.000581, train loss 4.0000, val loss 4.2283, time elapsed: 1169.01 seconds\n","step 2200: lr 0.000580, train loss 3.9459, val loss 4.2047, time elapsed: 1194.95 seconds\n","step 2250: lr 0.000579, train loss 4.0958, val loss 4.1125, time elapsed: 1220.90 seconds\n","step 2300: lr 0.000577, train loss 4.1375, val loss 4.1234, time elapsed: 1246.85 seconds\n","step 2350: lr 0.000576, train loss 4.2209, val loss 4.1697, time elapsed: 1272.80 seconds\n","step 2400: lr 0.000575, train loss 4.0164, val loss 4.0367, time elapsed: 1298.75 seconds\n","step 2450: lr 0.000574, train loss 4.1127, val loss 3.9612, time elapsed: 1324.69 seconds\n","step 2500: lr 0.000572, train loss 4.0946, val loss 4.0681, time elapsed: 1350.63 seconds\n","step 2550: lr 0.000571, train loss 4.0182, val loss 4.0087, time elapsed: 1376.57 seconds\n","step 2600: lr 0.000569, train loss 4.0164, val loss 4.0607, time elapsed: 1402.52 seconds\n","step 2650: lr 0.000568, train loss 3.9662, val loss 4.0907, time elapsed: 1428.46 seconds\n","step 2700: lr 0.000567, train loss 3.8777, val loss 4.0066, time elapsed: 1454.41 seconds\n","step 2750: lr 0.000565, train loss 3.9900, val loss 4.0560, time elapsed: 1480.36 seconds\n","step 2800: lr 0.000563, train loss 4.1387, val loss 3.9999, time elapsed: 1506.29 seconds\n","step 2850: lr 0.000562, train loss 3.9746, val loss 3.9976, time elapsed: 1532.24 seconds\n","step 2900: lr 0.000560, train loss 3.8185, val loss 3.9693, time elapsed: 1558.18 seconds\n","step 2950: lr 0.000559, train loss 3.8620, val loss 4.0162, time elapsed: 1584.12 seconds\n","step 3000: lr 0.000557, train loss 3.9998, val loss 4.0711, time elapsed: 1610.07 seconds\n","step 3050: lr 0.000555, train loss 4.1050, val loss 4.0326, time elapsed: 1636.01 seconds\n","step 3100: lr 0.000554, train loss 4.0619, val loss 3.9490, time elapsed: 1663.47 seconds\n","step 3150: lr 0.000552, train loss 3.9718, val loss 3.9870, time elapsed: 1689.41 seconds\n","step 3200: lr 0.000550, train loss 3.8876, val loss 3.9330, time elapsed: 1715.36 seconds\n","step 3250: lr 0.000548, train loss 3.6625, val loss 3.8611, time elapsed: 1741.30 seconds\n","step 3300: lr 0.000546, train loss 3.8923, val loss 4.0405, time elapsed: 1767.24 seconds\n","step 3350: lr 0.000545, train loss 4.2687, val loss 4.0006, time elapsed: 1793.18 seconds\n","step 3400: lr 0.000543, train loss 4.0887, val loss 3.9715, time elapsed: 1819.11 seconds\n","step 3450: lr 0.000541, train loss 3.9792, val loss 3.9589, time elapsed: 1845.06 seconds\n","step 3500: lr 0.000539, train loss 3.9895, val loss 4.0419, time elapsed: 1871.00 seconds\n","step 3550: lr 0.000537, train loss 3.8415, val loss 3.9082, time elapsed: 1896.95 seconds\n","step 3600: lr 0.000535, train loss 3.8754, val loss 3.8358, time elapsed: 1922.89 seconds\n","step 3650: lr 0.000533, train loss 3.7358, val loss 3.8840, time elapsed: 1948.83 seconds\n","step 3700: lr 0.000531, train loss 3.7051, val loss 3.8834, time elapsed: 1974.77 seconds\n","step 3750: lr 0.000529, train loss 3.9293, val loss 3.8425, time elapsed: 2000.71 seconds\n","step 3800: lr 0.000526, train loss 3.8515, val loss 3.8001, time elapsed: 2026.66 seconds\n","step 3850: lr 0.000524, train loss 3.8946, val loss 3.8595, time elapsed: 2052.60 seconds\n","step 3900: lr 0.000522, train loss 3.9338, val loss 3.8226, time elapsed: 2078.54 seconds\n","step 3950: lr 0.000520, train loss 3.8536, val loss 3.8210, time elapsed: 2104.48 seconds\n","step 4000: lr 0.000518, train loss 3.7765, val loss 3.8070, time elapsed: 2130.42 seconds\n","step 4050: lr 0.000516, train loss 3.7381, val loss 3.7521, time elapsed: 2156.36 seconds\n","step 4100: lr 0.000513, train loss 3.8073, val loss 3.7679, time elapsed: 2182.30 seconds\n","step 4150: lr 0.000511, train loss 3.8642, val loss 3.8585, time elapsed: 2208.24 seconds\n","step 4200: lr 0.000509, train loss 3.8494, val loss 3.8994, time elapsed: 2234.18 seconds\n","step 4250: lr 0.000506, train loss 3.9903, val loss 3.8188, time elapsed: 2260.12 seconds\n","step 4300: lr 0.000504, train loss 3.8577, val loss 3.7893, time elapsed: 2286.06 seconds\n","step 4350: lr 0.000501, train loss 3.8166, val loss 3.8033, time elapsed: 2312.00 seconds\n","step 4400: lr 0.000499, train loss 3.5677, val loss 3.8009, time elapsed: 2337.94 seconds\n","step 4450: lr 0.000497, train loss 3.8308, val loss 3.8569, time elapsed: 2363.87 seconds\n","step 4500: lr 0.000494, train loss 3.8816, val loss 3.8574, time elapsed: 2389.82 seconds\n","step 4550: lr 0.000492, train loss 3.8876, val loss 3.8385, time elapsed: 2415.75 seconds\n","step 4600: lr 0.000489, train loss 3.6678, val loss 3.7558, time elapsed: 2443.35 seconds\n","step 4650: lr 0.000487, train loss 3.9028, val loss 3.7745, time elapsed: 2469.30 seconds\n","step 4700: lr 0.000484, train loss 3.6702, val loss 3.7067, time elapsed: 2495.26 seconds\n","step 4750: lr 0.000482, train loss 3.6515, val loss 3.6489, time elapsed: 2521.22 seconds\n","step 4800: lr 0.000479, train loss 3.6268, val loss 3.7640, time elapsed: 2547.18 seconds\n","step 4850: lr 0.000476, train loss 3.6746, val loss 3.8487, time elapsed: 2573.14 seconds\n","step 4900: lr 0.000474, train loss 3.7051, val loss 3.8192, time elapsed: 2599.09 seconds\n","step 4950: lr 0.000471, train loss 3.8256, val loss 3.9366, time elapsed: 2625.04 seconds\n","step 5000: lr 0.000468, train loss 3.7559, val loss 3.7620, time elapsed: 2651.00 seconds\n","step 5050: lr 0.000466, train loss 3.7119, val loss 3.7603, time elapsed: 2676.96 seconds\n","step 5100: lr 0.000463, train loss 3.9085, val loss 3.7402, time elapsed: 2702.92 seconds\n","step 5150: lr 0.000460, train loss 3.6643, val loss 3.8662, time elapsed: 2728.87 seconds\n","step 5200: lr 0.000457, train loss 3.6111, val loss 3.6680, time elapsed: 2754.82 seconds\n","step 5250: lr 0.000455, train loss 3.8885, val loss 3.7649, time elapsed: 2780.78 seconds\n","step 5300: lr 0.000452, train loss 3.7909, val loss 3.7794, time elapsed: 2806.73 seconds\n","step 5350: lr 0.000449, train loss 3.7935, val loss 3.6598, time elapsed: 2832.69 seconds\n","step 5400: lr 0.000446, train loss 3.6224, val loss 3.7000, time elapsed: 2858.64 seconds\n","step 5450: lr 0.000443, train loss 3.7782, val loss 3.6532, time elapsed: 2884.60 seconds\n","step 5500: lr 0.000440, train loss 3.5666, val loss 3.6960, time elapsed: 2910.54 seconds\n","step 5550: lr 0.000438, train loss 3.5372, val loss 3.6707, time elapsed: 2936.49 seconds\n","step 5600: lr 0.000435, train loss 3.9107, val loss 3.7450, time elapsed: 2962.45 seconds\n","step 5650: lr 0.000432, train loss 3.7716, val loss 3.6624, time elapsed: 2988.40 seconds\n","step 5700: lr 0.000429, train loss 3.7156, val loss 3.6412, time elapsed: 3014.35 seconds\n","step 5750: lr 0.000426, train loss 4.0348, val loss 3.6168, time elapsed: 3040.31 seconds\n","step 5800: lr 0.000423, train loss 3.7746, val loss 3.5899, time elapsed: 3066.26 seconds\n","step 5850: lr 0.000420, train loss 3.9799, val loss 3.5677, time elapsed: 3092.21 seconds\n","step 5900: lr 0.000417, train loss 3.6460, val loss 3.6092, time elapsed: 3118.16 seconds\n","step 5950: lr 0.000414, train loss 3.6715, val loss 3.5602, time elapsed: 3144.12 seconds\n","step 6000: lr 0.000411, train loss 3.9022, val loss 3.7466, time elapsed: 3170.06 seconds\n","step 6050: lr 0.000408, train loss 3.7737, val loss 3.6014, time elapsed: 3196.02 seconds\n","step 6100: lr 0.000405, train loss 3.8074, val loss 3.5356, time elapsed: 3221.98 seconds\n","step 6150: lr 0.000402, train loss 3.7598, val loss 3.5078, time elapsed: 3249.40 seconds\n","step 6200: lr 0.000399, train loss 3.5916, val loss 3.5504, time elapsed: 3275.34 seconds\n","step 6250: lr 0.000396, train loss 3.6942, val loss 3.5274, time elapsed: 3301.28 seconds\n","step 6300: lr 0.000393, train loss 3.6253, val loss 3.4858, time elapsed: 3327.21 seconds\n","step 6350: lr 0.000390, train loss 3.7029, val loss 3.6927, time elapsed: 3353.16 seconds\n","step 6400: lr 0.000386, train loss 3.7240, val loss 3.5512, time elapsed: 3379.10 seconds\n","step 6450: lr 0.000383, train loss 3.7337, val loss 3.5798, time elapsed: 3405.05 seconds\n","step 6500: lr 0.000380, train loss 3.6461, val loss 3.8238, time elapsed: 3430.99 seconds\n","step 6550: lr 0.000377, train loss 3.6345, val loss 3.5924, time elapsed: 3456.93 seconds\n","step 6600: lr 0.000374, train loss 3.6257, val loss 3.5834, time elapsed: 3482.87 seconds\n","step 6650: lr 0.000371, train loss 3.5748, val loss 3.5892, time elapsed: 3508.81 seconds\n","step 6700: lr 0.000368, train loss 3.7101, val loss 3.6095, time elapsed: 3534.76 seconds\n","step 6750: lr 0.000364, train loss 3.6058, val loss 3.7433, time elapsed: 3560.70 seconds\n","step 6800: lr 0.000361, train loss 3.7157, val loss 3.6047, time elapsed: 3586.64 seconds\n","step 6850: lr 0.000358, train loss 3.6921, val loss 3.5679, time elapsed: 3612.59 seconds\n","step 6900: lr 0.000355, train loss 3.5598, val loss 3.5934, time elapsed: 3638.53 seconds\n","step 6950: lr 0.000352, train loss 3.4595, val loss 3.5809, time elapsed: 3664.47 seconds\n","step 7000: lr 0.000348, train loss 3.4227, val loss 3.5436, time elapsed: 3690.41 seconds\n","step 7050: lr 0.000345, train loss 3.5575, val loss 3.5850, time elapsed: 3716.35 seconds\n","step 7100: lr 0.000342, train loss 3.6780, val loss 3.6312, time elapsed: 3742.30 seconds\n","step 7150: lr 0.000339, train loss 3.5162, val loss 3.6317, time elapsed: 3768.24 seconds\n","step 7200: lr 0.000336, train loss 3.4520, val loss 3.5725, time elapsed: 3794.18 seconds\n","step 7250: lr 0.000332, train loss 3.7549, val loss 3.4988, time elapsed: 3820.12 seconds\n","step 7300: lr 0.000329, train loss 3.7000, val loss 3.5377, time elapsed: 3846.06 seconds\n","step 7350: lr 0.000326, train loss 3.5850, val loss 3.5311, time elapsed: 3872.01 seconds\n","step 7400: lr 0.000323, train loss 3.4766, val loss 3.4991, time elapsed: 3897.95 seconds\n","step 7450: lr 0.000319, train loss 3.6656, val loss 3.5645, time elapsed: 3923.89 seconds\n","step 7500: lr 0.000316, train loss 3.7515, val loss 3.5771, time elapsed: 3949.83 seconds\n","step 7550: lr 0.000313, train loss 3.5644, val loss 3.4955, time elapsed: 3975.77 seconds\n","step 7600: lr 0.000310, train loss 3.6271, val loss 3.4069, time elapsed: 4001.71 seconds\n","step 7650: lr 0.000306, train loss 3.5291, val loss 3.5136, time elapsed: 4029.40 seconds\n","step 7700: lr 0.000303, train loss 3.4353, val loss 3.5314, time elapsed: 4055.35 seconds\n","step 7750: lr 0.000300, train loss 3.6161, val loss 3.6917, time elapsed: 4081.28 seconds\n","step 7800: lr 0.000297, train loss 3.4994, val loss 3.6308, time elapsed: 4107.22 seconds\n","step 7850: lr 0.000293, train loss 3.6401, val loss 3.5676, time elapsed: 4133.16 seconds\n","step 7900: lr 0.000290, train loss 3.6511, val loss 3.5383, time elapsed: 4159.10 seconds\n","step 7950: lr 0.000287, train loss 3.6480, val loss 3.6554, time elapsed: 4185.05 seconds\n","step 8000: lr 0.000284, train loss 3.5194, val loss 3.6613, time elapsed: 4210.99 seconds\n","step 8050: lr 0.000280, train loss 3.5770, val loss 3.6211, time elapsed: 4236.94 seconds\n","step 8100: lr 0.000277, train loss 3.4331, val loss 3.6693, time elapsed: 4262.87 seconds\n","step 8150: lr 0.000274, train loss 3.5182, val loss 3.6121, time elapsed: 4288.81 seconds\n","step 8200: lr 0.000271, train loss 3.7657, val loss 3.6980, time elapsed: 4314.76 seconds\n","step 8250: lr 0.000267, train loss 3.6707, val loss 3.6709, time elapsed: 4340.70 seconds\n","step 8300: lr 0.000264, train loss 3.5607, val loss 3.6208, time elapsed: 4366.65 seconds\n","step 8350: lr 0.000261, train loss 3.5308, val loss 3.6124, time elapsed: 4392.60 seconds\n","step 8400: lr 0.000258, train loss 3.6706, val loss 3.6508, time elapsed: 4418.55 seconds\n","step 8450: lr 0.000255, train loss 3.5037, val loss 3.5698, time elapsed: 4444.49 seconds\n","step 8500: lr 0.000251, train loss 3.4597, val loss 3.5673, time elapsed: 4470.43 seconds\n","step 8550: lr 0.000248, train loss 3.6092, val loss 3.7483, time elapsed: 4496.37 seconds\n","step 8600: lr 0.000245, train loss 3.5641, val loss 3.7077, time elapsed: 4522.32 seconds\n","step 8650: lr 0.000242, train loss 3.5337, val loss 3.7208, time elapsed: 4548.26 seconds\n","step 8700: lr 0.000239, train loss 3.5097, val loss 3.5309, time elapsed: 4574.20 seconds\n","step 8750: lr 0.000235, train loss 3.5974, val loss 3.5451, time elapsed: 4600.14 seconds\n","step 8800: lr 0.000232, train loss 3.5083, val loss 3.6073, time elapsed: 4626.08 seconds\n","step 8850: lr 0.000229, train loss 3.4367, val loss 3.6550, time elapsed: 4652.02 seconds\n","step 8900: lr 0.000226, train loss 3.5688, val loss 3.6405, time elapsed: 4677.96 seconds\n","step 8950: lr 0.000223, train loss 3.5553, val loss 3.6542, time elapsed: 4703.91 seconds\n","step 9000: lr 0.000220, train loss 3.6265, val loss 3.5943, time elapsed: 4729.85 seconds\n","step 9050: lr 0.000217, train loss 3.5635, val loss 3.5012, time elapsed: 4755.80 seconds\n","step 9100: lr 0.000213, train loss 3.4516, val loss 3.5857, time elapsed: 4781.75 seconds\n","step 9150: lr 0.000210, train loss 3.5818, val loss 3.5649, time elapsed: 4807.70 seconds\n","step 9200: lr 0.000207, train loss 3.3549, val loss 3.6002, time elapsed: 4836.20 seconds\n","step 9250: lr 0.000204, train loss 3.4571, val loss 3.5121, time elapsed: 4862.13 seconds\n","step 9300: lr 0.000201, train loss 3.4340, val loss 3.5999, time elapsed: 4888.07 seconds\n","step 9350: lr 0.000198, train loss 3.6614, val loss 3.5317, time elapsed: 4914.01 seconds\n","step 9400: lr 0.000195, train loss 3.5837, val loss 3.5609, time elapsed: 4939.95 seconds\n","step 9450: lr 0.000192, train loss 3.5354, val loss 3.6186, time elapsed: 4965.90 seconds\n","step 9500: lr 0.000189, train loss 3.6315, val loss 3.5536, time elapsed: 4991.85 seconds\n","step 9550: lr 0.000186, train loss 3.3447, val loss 3.5813, time elapsed: 5017.78 seconds\n","step 9600: lr 0.000183, train loss 3.5409, val loss 3.5563, time elapsed: 5043.72 seconds\n","step 9650: lr 0.000180, train loss 3.6296, val loss 3.6031, time elapsed: 5069.65 seconds\n","step 9700: lr 0.000177, train loss 3.5337, val loss 3.4635, time elapsed: 5095.60 seconds\n","step 9750: lr 0.000174, train loss 3.6117, val loss 3.5407, time elapsed: 5121.54 seconds\n","step 9800: lr 0.000171, train loss 3.5694, val loss 3.5227, time elapsed: 5147.47 seconds\n","step 9850: lr 0.000168, train loss 3.4622, val loss 3.5813, time elapsed: 5173.42 seconds\n","step 9900: lr 0.000165, train loss 3.4459, val loss 3.6705, time elapsed: 5199.36 seconds\n","step 9950: lr 0.000162, train loss 3.5918, val loss 3.5766, time elapsed: 5225.30 seconds\n","step 10000: lr 0.000159, train loss 3.3111, val loss 3.6867, time elapsed: 5251.24 seconds\n","step 10050: lr 0.000157, train loss 3.5404, val loss 3.5727, time elapsed: 5277.18 seconds\n","step 10100: lr 0.000154, train loss 3.4609, val loss 3.5724, time elapsed: 5303.12 seconds\n","step 10150: lr 0.000151, train loss 3.2999, val loss 3.4736, time elapsed: 5329.06 seconds\n","step 10200: lr 0.000148, train loss 3.5100, val loss 3.5234, time elapsed: 5355.01 seconds\n","step 10250: lr 0.000145, train loss 3.4336, val loss 3.4893, time elapsed: 5380.94 seconds\n","step 10300: lr 0.000143, train loss 3.4649, val loss 3.4224, time elapsed: 5406.88 seconds\n","step 10350: lr 0.000140, train loss 3.4829, val loss 3.5367, time elapsed: 5432.82 seconds\n","step 10400: lr 0.000137, train loss 3.2108, val loss 3.5033, time elapsed: 5458.76 seconds\n","step 10450: lr 0.000134, train loss 3.6529, val loss 3.4587, time elapsed: 5484.70 seconds\n","step 10500: lr 0.000132, train loss 3.4609, val loss 3.4504, time elapsed: 5510.64 seconds\n","step 10550: lr 0.000129, train loss 3.4038, val loss 3.5053, time elapsed: 5536.58 seconds\n","step 10600: lr 0.000126, train loss 3.4228, val loss 3.5475, time elapsed: 5562.52 seconds\n","step 10650: lr 0.000124, train loss 3.4097, val loss 3.5689, time elapsed: 5588.46 seconds\n","step 10700: lr 0.000121, train loss 3.5136, val loss 3.5676, time elapsed: 5616.05 seconds\n","step 10750: lr 0.000118, train loss 3.2754, val loss 3.5055, time elapsed: 5641.98 seconds\n","step 10800: lr 0.000116, train loss 3.5457, val loss 3.4551, time elapsed: 5667.92 seconds\n","step 10850: lr 0.000113, train loss 3.4508, val loss 3.4806, time elapsed: 5693.86 seconds\n","step 10900: lr 0.000111, train loss 3.5039, val loss 3.4025, time elapsed: 5719.81 seconds\n","step 10950: lr 0.000108, train loss 3.4030, val loss 3.6080, time elapsed: 5745.75 seconds\n","step 11000: lr 0.000106, train loss 3.4259, val loss 3.4366, time elapsed: 5771.70 seconds\n","step 11050: lr 0.000103, train loss 3.4935, val loss 3.5094, time elapsed: 5797.64 seconds\n","step 11100: lr 0.000101, train loss 3.4438, val loss 3.4371, time elapsed: 5823.57 seconds\n","step 11150: lr 0.000098, train loss 3.3767, val loss 3.5458, time elapsed: 5849.51 seconds\n","step 11200: lr 0.000096, train loss 3.4958, val loss 3.5059, time elapsed: 5875.45 seconds\n","step 11250: lr 0.000094, train loss 3.5926, val loss 3.5421, time elapsed: 5901.40 seconds\n","step 11300: lr 0.000091, train loss 3.4183, val loss 3.5524, time elapsed: 5927.33 seconds\n","step 11350: lr 0.000089, train loss 3.4487, val loss 3.5655, time elapsed: 5953.28 seconds\n","step 11400: lr 0.000087, train loss 3.5088, val loss 3.5500, time elapsed: 5979.23 seconds\n","step 11450: lr 0.000084, train loss 4.0365, val loss 3.5290, time elapsed: 6005.17 seconds\n","step 11500: lr 0.000082, train loss 3.2558, val loss 3.5474, time elapsed: 6031.10 seconds\n","step 11550: lr 0.000080, train loss 3.5223, val loss 3.4696, time elapsed: 6057.04 seconds\n","step 11600: lr 0.000078, train loss 3.4855, val loss 3.4515, time elapsed: 6082.99 seconds\n","step 11650: lr 0.000076, train loss 3.4373, val loss 3.5097, time elapsed: 6108.92 seconds\n","step 11700: lr 0.000073, train loss 3.6221, val loss 3.4565, time elapsed: 6134.86 seconds\n","step 11750: lr 0.000071, train loss 3.4546, val loss 3.4198, time elapsed: 6160.80 seconds\n","step 11800: lr 0.000069, train loss 3.4311, val loss 3.3793, time elapsed: 6186.73 seconds\n","step 11850: lr 0.000067, train loss 3.7588, val loss 3.3885, time elapsed: 6212.67 seconds\n","step 11900: lr 0.000065, train loss 3.4169, val loss 3.5386, time elapsed: 6238.60 seconds\n","step 11950: lr 0.000063, train loss 3.4953, val loss 3.4546, time elapsed: 6264.54 seconds\n","step 12000: lr 0.000061, train loss 3.7284, val loss 3.4440, time elapsed: 6290.48 seconds\n","step 12050: lr 0.000060, train loss 3.5286, val loss 3.4886, time elapsed: 6316.42 seconds\n","step 12100: lr 0.000060, train loss 3.3839, val loss 3.4139, time elapsed: 6342.37 seconds\n","step 12150: lr 0.000060, train loss 3.3782, val loss 3.4443, time elapsed: 6368.31 seconds\n","step 12200: lr 0.000060, train loss 3.3825, val loss 3.4914, time elapsed: 6394.25 seconds\n","step 12250: lr 0.000060, train loss 3.3356, val loss 3.4870, time elapsed: 6422.56 seconds\n","step 12300: lr 0.000060, train loss 3.5233, val loss 3.4337, time elapsed: 6448.50 seconds\n","step 12350: lr 0.000060, train loss 3.5487, val loss 3.4231, time elapsed: 6474.43 seconds\n","step 12400: lr 0.000060, train loss 3.4802, val loss 3.4461, time elapsed: 6500.36 seconds\n","step 12450: lr 0.000060, train loss 3.4572, val loss 3.4237, time elapsed: 6526.31 seconds\n","step 12500: lr 0.000060, train loss 3.4514, val loss 3.3877, time elapsed: 6552.24 seconds\n","step 12550: lr 0.000060, train loss 3.4563, val loss 3.4796, time elapsed: 6578.19 seconds\n","step 12600: lr 0.000060, train loss 3.2146, val loss 3.3739, time elapsed: 6604.12 seconds\n","step 12650: lr 0.000060, train loss 3.2772, val loss 3.3973, time elapsed: 6630.06 seconds\n","step 12700: lr 0.000060, train loss 3.3844, val loss 3.4458, time elapsed: 6656.00 seconds\n","step 12750: lr 0.000060, train loss 3.4702, val loss 3.5227, time elapsed: 6681.94 seconds\n","step 12800: lr 0.000060, train loss 3.5700, val loss 3.5103, time elapsed: 6707.89 seconds\n","step 12850: lr 0.000060, train loss 3.5072, val loss 3.4463, time elapsed: 6733.82 seconds\n","step 12900: lr 0.000060, train loss 3.3582, val loss 3.4900, time elapsed: 6759.77 seconds\n","step 12950: lr 0.000060, train loss 3.3729, val loss 3.4689, time elapsed: 6785.70 seconds\n","step 13000: lr 0.000060, train loss 3.3846, val loss 3.4622, time elapsed: 6811.63 seconds\n","step 13050: lr 0.000060, train loss 3.5953, val loss 3.4851, time elapsed: 6837.57 seconds\n","step 13100: lr 0.000060, train loss 3.4658, val loss 3.5545, time elapsed: 6863.50 seconds\n","step 13150: lr 0.000060, train loss 3.5199, val loss 3.3761, time elapsed: 6889.43 seconds\n","step 13200: lr 0.000060, train loss 3.5054, val loss 3.5090, time elapsed: 6915.36 seconds\n","step 13250: lr 0.000060, train loss 3.3987, val loss 3.3976, time elapsed: 6941.30 seconds\n","step 13300: lr 0.000060, train loss 2.8739, val loss 3.3981, time elapsed: 6967.23 seconds\n","step 13350: lr 0.000060, train loss 3.2703, val loss 3.4710, time elapsed: 6993.16 seconds\n","step 13400: lr 0.000060, train loss 3.3745, val loss 3.4393, time elapsed: 7019.09 seconds\n","step 13450: lr 0.000060, train loss 3.6106, val loss 3.3551, time elapsed: 7045.03 seconds\n","step 13500: lr 0.000060, train loss 3.6099, val loss 3.3986, time elapsed: 7070.97 seconds\n","step 13550: lr 0.000060, train loss 3.5966, val loss 3.3721, time elapsed: 7096.90 seconds\n","step 13600: lr 0.000060, train loss 3.3733, val loss 3.2353, time elapsed: 7122.84 seconds\n","step 13650: lr 0.000060, train loss 3.4608, val loss 3.3934, time elapsed: 7148.77 seconds\n","step 13700: lr 0.000060, train loss 3.3312, val loss 3.3664, time elapsed: 7174.70 seconds\n","step 13750: lr 0.000060, train loss 3.4031, val loss 3.3809, time elapsed: 7203.23 seconds\n","step 13800: lr 0.000060, train loss 3.4164, val loss 3.3713, time elapsed: 7229.16 seconds\n","step 13850: lr 0.000060, train loss 3.5288, val loss 3.3975, time elapsed: 7255.09 seconds\n","step 13900: lr 0.000060, train loss 3.3943, val loss 3.2856, time elapsed: 7281.03 seconds\n","step 13950: lr 0.000060, train loss 3.3921, val loss 3.3656, time elapsed: 7306.97 seconds\n","step 14000: lr 0.000060, train loss 3.4406, val loss 3.3361, time elapsed: 7332.90 seconds\n","step 14050: lr 0.000060, train loss 3.2593, val loss 3.3606, time elapsed: 7358.84 seconds\n","step 14100: lr 0.000060, train loss 3.3955, val loss 3.4944, time elapsed: 7384.77 seconds\n","step 14150: lr 0.000060, train loss 3.4461, val loss 3.3731, time elapsed: 7410.70 seconds\n","step 14200: lr 0.000060, train loss 3.4889, val loss 3.3075, time elapsed: 7436.64 seconds\n","step 14250: lr 0.000060, train loss 3.4956, val loss 3.3260, time elapsed: 7462.57 seconds\n","step 14300: lr 0.000060, train loss 3.4563, val loss 3.3903, time elapsed: 7488.51 seconds\n","step 14350: lr 0.000060, train loss 3.4286, val loss 3.4536, time elapsed: 7514.45 seconds\n","step 14400: lr 0.000060, train loss 3.4516, val loss 3.4147, time elapsed: 7540.39 seconds\n","step 14450: lr 0.000060, train loss 3.3409, val loss 3.3077, time elapsed: 7566.33 seconds\n","step 14500: lr 0.000060, train loss 3.2300, val loss 3.3867, time elapsed: 7592.27 seconds\n","step 14550: lr 0.000060, train loss 3.6719, val loss 3.3707, time elapsed: 7618.21 seconds\n","step 14600: lr 0.000060, train loss 3.4471, val loss 3.4149, time elapsed: 7644.15 seconds\n","step 14650: lr 0.000060, train loss 3.6058, val loss 3.3934, time elapsed: 7670.08 seconds\n","step 14700: lr 0.000060, train loss 3.4029, val loss 3.3647, time elapsed: 7696.02 seconds\n","step 14750: lr 0.000060, train loss 3.3684, val loss 3.3340, time elapsed: 7721.96 seconds\n","step 14800: lr 0.000060, train loss 3.2516, val loss 3.3803, time elapsed: 7747.90 seconds\n","step 14850: lr 0.000060, train loss 3.1508, val loss 3.3892, time elapsed: 7773.83 seconds\n","step 14900: lr 0.000060, train loss 3.4349, val loss 3.2884, time elapsed: 7799.77 seconds\n","step 14950: lr 0.000060, train loss 3.4333, val loss 3.3042, time elapsed: 7825.70 seconds\n","step 14999: lr 0.000060, train loss 3.4342, val loss 3.2999, time elapsed: 7851.14 seconds\n"]}]},{"cell_type":"code","source":["#Save the model\n","if master_process:\n","    print(\"SAVING MODEL\")\n","    raw_model = model.module if ddp else model # always contains the \"raw\" unwrapped model\n","\n","    input_str = \"Hello, I am Mr. LLM. I \"\n","    output = raw_model.generate(\n","        input_str,\n","        max_gen_len = 50 + len(input_str),\n","        temperature = 0.6,\n","        top_p = 0.9,\n","        top_k = 32,\n","    )\n","    print(\"----------------\")\n","    print(output)\n","\n","    input_str = \"These are the symptoms of HIV. \"\n","    output = raw_model.generate(\n","        input_str,\n","        max_gen_len = 50 + len(input_str),\n","        temperature = 0.6,\n","        top_p = 0.9,\n","        top_k = 32,\n","    )\n","    print(\"----------------\")\n","    print(output)\n","\n","    input_str = \"Here is a story about a pirate and a ninja. \"\n","    output = raw_model.generate(\n","        input_str,\n","        max_gen_len = 200 + len(input_str),\n","        temperature = 0.6,\n","        top_p = 0.9,\n","        top_k = 32,\n","    )\n","    print(\"----------------\")\n","    print(output)\n","\n","    os.makedirs(\"working\", exist_ok=True)\n","    os.makedirs(\"download\", exist_ok=True)\n","    torch.save(raw_model.state_dict(), './working/best_model_state-114m.bin')"],"metadata":{"id":"iP5Rp9yINpDW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735373754017,"user_tz":-540,"elapsed":5939,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"cc8344cb-cc47-4ff4-b7ce-a0f257e20d4c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["SAVING MODEL\n","----------------\n","Hello, I am Mr. LLM. I __________\n","The first thing to do is to read the text in the dictionary. I want to read the text in the dictionary. I want to read the text in the dictionary. I want to read the text in the dictionary. I want to read the text in the dictionary. I want to read the text in the dictionary. I want to read the text\n","----------------\n","These are the symptoms of HIV. \n","The symptoms of HIV may vary, but they may vary depending on the person's age, sex, and other factors.\n","People with HIV are more likely to develop HIV if they have a family history of HIV, which is the most common reason for HIV infection.\n","Some people with HIV may have a family history of HIV.\n","The HIV infection may affect a person's ability to function, or\n","----------------\n","Here is a story about a pirate and a ninja. \n","The story goes on to explain how he was a great warrior and how he was a very successful pirate. \n","He was a good man and he was a good man. He was a good man and he was a good man.\n","The story goes on to explain how he was a good man and how he was a good man.\n","He was a good man and he was a good man. He was a good man and he was a good man.\n","The story goes on to explain how he was a great warrior and how he was a good man.\n","He was a good man and he was a good man. He was a good man and he was a good man.\n","The story goes on to explain how he was a good man and how he was a good man.\n","The story goes on to explain how he was a good man and how he was a good man.\n","The story goes on to explain how he was a good man and how he was a good man.\n","The story goes on to explain how he was a good man and how he was a good man.\n","The story goes on to explain how he was a good man and how he was a good man\n"]}]},{"cell_type":"code","source":["#exit gracefully\n","if ddp:\n","    destroy_process_group()"],"metadata":{"id":"U81MKQXmzpJg","executionInfo":{"status":"ok","timestamp":1735373807756,"user_tz":-540,"elapsed":512,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eeucXcx4MeEy"},"execution_count":null,"outputs":[]}]}